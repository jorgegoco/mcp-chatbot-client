# ğŸ¤– MCP Chatbot Client

<div align="center">

### **Connect Claude AI to Unlimited MCP Servers**

A production-ready Python chatbot leveraging the **Model Context Protocol** to dynamically discover and use tools from any MCP-compatible server.

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-green.svg)](https://modelcontextprotocol.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[Features](#-features) â€¢
[Quick Start](#-quick-start) â€¢
[Architecture](#-architecture) â€¢
[Usage](#-usage) â€¢
[Configuration](#-configuration) â€¢
[Contributing](#-contributing)

</div>

---

## ğŸ¯ The Problem MCP Solves

### Before MCP: The MÃ—N Integration Problem

```mermaid
graph TB
    subgraph "5 AI Applications"
        A1[Claude Desktop]
        A2[VSCode]
        A3[Cursor]
        A4[Windsurf]
        A5[Custom App]
    end

    subgraph "10 Tools"
        T1[GitHub]
        T2[Slack]
        T3[Database]
        T4[FileSystem]
        T5[Web Search]
        T6[Email]
        T7[Calendar]
        T8[CRM]
        T9[Analytics]
        T10[Cloud Storage]
    end

    A1 -.Custom Integration.-> T1
    A1 -.Custom Integration.-> T2
    A1 -.Custom Integration.-> T3
    A2 -.Custom Integration.-> T1
    A2 -.Custom Integration.-> T4
    A3 -.Custom Integration.-> T5

    style A1 fill:#e1f5fe
    style A2 fill:#e1f5fe
    style A3 fill:#e1f5fe
    style T1 fill:#f3e5f5
    style T2 fill:#f3e5f5
    style T3 fill:#f3e5f5

    Note1[5 Apps Ã— 10 Tools = 50 integrations ğŸ˜±]

    style Note1 fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### With MCP: The M+N Solution

```mermaid
graph LR
    subgraph "AI Applications"
        A1[Claude Desktop]
        A2[VSCode]
        A3[Cursor]
        A4[Custom App]
    end

    subgraph "MCP Protocol"
        MCP[Model Context Protocol]
    end

    subgraph "MCP Servers"
        S1[GitHub Server]
        S2[Slack Server]
        S3[FileSystem Server]
        S4[Web Search Server]
    end

    A1 --> MCP
    A2 --> MCP
    A3 --> MCP
    A4 --> MCP

    MCP --> S1
    MCP --> S2
    MCP --> S3
    MCP --> S4

    style MCP fill:#4caf50,stroke:#2e7d32,stroke-width:3px,color:#fff
    style A1 fill:#e1f5fe
    style A2 fill:#e1f5fe
    style A3 fill:#e1f5fe
    style A4 fill:#e1f5fe
    style S1 fill:#f3e5f5
    style S2 fill:#f3e5f5
    style S3 fill:#f3e5f5
    style S4 fill:#f3e5f5

    Note2[4 Apps + 4 Servers = 8 integrations ğŸ‰]

    style Note2 fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
```

> **MCP is like USB for AI** - a universal standard that makes AI integrations plug-and-play!

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ”Œ **Multi-Server Architecture**

Connect to unlimited MCP servers simultaneously with dynamic discovery

### ğŸ¯ **Zero Configuration**

Add new servers via JSON config - no code changes needed

### ğŸ¤– **Claude AI Powered**

Leverages Anthropic's latest models with tool calling

</td>
<td width="50%">

### âš¡ **AsyncExitStack Pattern**

Scalable async architecture for production use

### ğŸ›¡ï¸ **Robust & Resilient**

Individual server failures don't crash the application

### ğŸ”’ **Secure by Design**

Environment variables, sandboxed file access, API key protection

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

### System Overview

```mermaid
flowchart TB
    User([ğŸ‘¤ User])

    subgraph ChatBot["ğŸ¤– MCP Chatbot Client"]
        Config[ğŸ“‹ Load server_config.json]
        Launch[ğŸš€ Launch MCP Servers]
        Discover[ğŸ” Discover Tools]
        Chat[ğŸ’¬ Interactive Chat Loop]

        Config --> Launch
        Launch --> Discover
        Discover --> Chat
    end

    subgraph Servers["MCP Servers (Subprocesses)"]
        FS[ğŸ“ Filesystem Server<br/>Node.js via npx]
        Fetch[ğŸŒ Fetch Server<br/>Python via uvx]
        Custom[ğŸ”§ Custom Servers<br/>Your tools]
    end

    subgraph Claude["ğŸ§  Claude AI"]
        API[Anthropic API<br/>claude-sonnet-4]
    end

    User <-->|Natural Language| Chat
    Chat <-->|Messages + Tools| API
    Chat -->|Tool Calls| FS
    Chat -->|Tool Calls| Fetch
    Chat -->|Tool Calls| Custom

    FS -->|Results| Chat
    Fetch -->|Results| Chat
    Custom -->|Results| Chat

    style ChatBot fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Servers fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Claude fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style User fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
```

### Conversation Flow

```mermaid
sequenceDiagram
    participant User
    participant Chatbot
    participant Claude
    participant MCPServer as MCP Server<br/>(filesystem)

    User->>Chatbot: "Read the README.md file"

    Chatbot->>Claude: Send message + available tools
    Note over Claude: Analyzes request<br/>Decides to use read_file

    Claude->>Chatbot: Tool call: read_file(path="README.md")

    Chatbot->>MCPServer: Execute: read_file
    Note over MCPServer: Reads file from disk

    MCPServer->>Chatbot: File content

    Chatbot->>Claude: Tool result + content
    Note over Claude: Processes result<br/>Generates response

    Claude->>Chatbot: Final response

    Chatbot->>User: "I've read your README..."

    rect rgb(200, 255, 200)
    Note over User,MCPServer: âœ… Complete conversation with tool usage
    end
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.13+**
- **Node.js 18+** (for npx-based servers)
- **[uv](https://github.com/astral-sh/uv)** package manager
- **[Anthropic API Key](https://console.anthropic.com/)**

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/mcp-chatbot-client.git
cd mcp-chatbot-client

# Install dependencies
uv sync

# Configure API key
echo "ANTHROPIC_API_KEY=your_api_key_here" > .env

# Run!
uv run python main.py
```

### First Run Output

```
ğŸš€ Setting up MCP Chatbot...
==================================================
âœ… Loaded configuration from server_config.json
ğŸ“‹ Found 2 server(s)

ğŸ”Œ Connecting to 'filesystem' server...
âœ… Connected to 'filesystem' with 3 tool(s)

ğŸ”Œ Connecting to 'fetch' server...
âœ… Connected to 'fetch' with 1 tool(s)

==================================================
âœ… Setup complete! 4 total tools available
==================================================

ğŸ¤– MCP Chatbot Ready!

You: _
```

---

## ğŸ’¬ Usage

### Interactive Commands

| Command              | Description                                     |
| -------------------- | ----------------------------------------------- |
| `tools`              | View all available tools from connected servers |
| `quit` or `exit`     | Gracefully exit the chatbot                     |
| `<natural language>` | Chat with Claude using MCP tools                |

### Example Conversations

#### ğŸ“– Read a File

```
You: Read the README.md file

ğŸ”§ Calling tool 'read_file' with args: {'path': 'README.md'}
âœ… Tool executed

Claude: I've read your README.md file. It describes an MCP chatbot
        client that connects Claude AI to external MCP servers...
```

#### ğŸŒ Fetch Web Content

```
You: Fetch https://www.anthropic.com and summarize the content

ğŸ”§ Calling tool 'fetch' with args: {'url': 'https://www.anthropic.com'}
âœ… Tool executed

Claude: Anthropic is an AI safety company. Their website describes their
        mission to build reliable, interpretable, and steerable AI systems...
```

#### ğŸ“ Multi-Step Operations

```
You: List all Python files in this directory, then create a summary document

ğŸ”§ Calling tool 'list_directory' with args: {'path': '.'}
âœ… Tool executed

ğŸ”§ Calling tool 'write_file' with args: {'path': 'summary.txt', ...}
âœ… Tool executed

Claude: I've analyzed the directory and created summary.txt with details
        about all 3 Python files found...
```

---

## âš™ï¸ Configuration

### Server Configuration File

Create `server_config.json` in your project root:

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "."],
      "env": {}
    },
    "fetch": {
      "command": "uvx",
      "args": ["--quiet", "mcp-server-fetch"],
      "env": {}
    }
  }
}
```

### Configuration Schema

```mermaid
graph TD
    Config[server_config.json]

    Config --> Servers[mcpServers Object]

    Servers --> Server1[Server 1<br/>e.g., 'filesystem']
    Servers --> Server2[Server 2<br/>e.g., 'fetch']
    Servers --> ServerN[Server N<br/>e.g., 'custom']

    Server1 --> Cmd1[command: string]
    Server1 --> Args1[args: array]
    Server1 --> Env1[env: object<br/>optional]

    style Config fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style Servers fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style Server1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Server2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style ServerN fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
```

### Adding More Servers

**Just update the JSON - no code changes needed!**

```json
{
  "mcpServers": {
    "filesystem": {...},
    "fetch": {...},
    "brave-search": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-brave-search"],
      "env": {
        "BRAVE_API_KEY": "your_api_key"
      }
    },
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_TOKEN": "your_token"
      }
    }
  }
}
```

### Available MCP Servers

Explore the **[MCP Server Registry](https://github.com/modelcontextprotocol/servers)**:

| Server              | Description                         | Provider  |
| ------------------- | ----------------------------------- | --------- |
| ğŸ“ **filesystem**   | File operations (read, write, list) | Anthropic |
| ğŸŒ **fetch**        | Web content as markdown             | Anthropic |
| ğŸ” **brave-search** | Web search                          | Anthropic |
| ğŸ™ **github**       | Repository management               | Anthropic |
| ğŸ“Š **sqlite**       | Database queries                    | Anthropic |
| ğŸ’¬ **slack**        | Team communication                  | Community |
| ğŸ˜ **postgres**     | PostgreSQL access                   | Community |

---

## ğŸ¨ Key Design Patterns

### AsyncExitStack Pattern

**The Problem:** Can't dynamically manage async contexts in a loop with nested `async with` blocks.

**The Solution:**

```mermaid
graph LR
    subgraph "Traditional Nested (âŒ Doesn't Scale)"
        N1[async with server1:]
        N2[async with server2:]
        N3[async with server3:]
        N1 --> N2
        N2 --> N3
        N3 --> Loop1[chat_loop]

        Note1[Nesting depth = # of servers]

        style N1 fill:#ffebee
        style N2 fill:#ffebee
        style N3 fill:#ffebee
        style Note1 fill:#ffebee,stroke:#c62828
    end

    subgraph "AsyncExitStack (âœ… Scalable)"
        S1[async with AsyncExitStack]
        S2[for server in servers:<br/>stack.enter_async_context]
        S1 --> S2
        S2 --> Loop2[chat_loop]

        Note2[Constant depth = 2<br/>Unlimited servers!]

        style S1 fill:#e8f5e9
        style S2 fill:#e8f5e9
        style Loop2 fill:#e8f5e9
        style Note2 fill:#e8f5e9,stroke:#2e7d32
    end
```

**Implementation:**

```python
async def connect_to_servers_and_run(self):
    async with AsyncExitStack() as stack:
        # Dynamically add unlimited servers
        for server_name, config in servers.items():
            read, write = await stack.enter_async_context(
                stdio_client(server_params)
            )
            session = await stack.enter_async_context(
                ClientSession(read, write)
            )
            # All contexts stay alive!

        # Run chat with all servers connected
        await self.chat_loop()
```

---

## ğŸ’° Cost Optimization

### Model Comparison

```mermaid
graph TB
    subgraph Models["Claude Models"]
        Haiku[âš¡ Haiku 4.5<br/>$1 / $5 per MTok<br/>Fast & Cheap]
        Sonnet[ğŸš€ Sonnet 4.5<br/>$3 / $15 per MTok<br/>Balanced]
        Opus[ğŸ¯ Opus 4<br/>$15 / $75 per MTok<br/>Premium]
    end

    subgraph Usage["Use Cases"]
        Dev[ğŸ§ª Testing &<br/>Development]
        Prod[ğŸ­ Production<br/>Applications]
        Premium[ğŸ’ Critical<br/>Tasks]
    end

    Haiku -.->|Recommended| Dev
    Sonnet -.->|Recommended| Prod
    Opus -.->|Recommended| Premium

    style Haiku fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style Sonnet fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Opus fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px

    Note[ğŸ’¡ Haiku is 67% cheaper than Sonnet!]
    style Note fill:#fff3e0,stroke:#f57c00,stroke-width:2px
```

### Switching Models

In `chatbot.py`, update the model parameter (appears in 2 locations):

```python
# For testing (cheaper):
model='claude-haiku-4-5-20251001'

# For production (better quality):
model='claude-sonnet-4-20250514'
```

**Cost Savings Example:**

- 1000 queries with Haiku: ~$10
- 1000 queries with Sonnet: ~$30
- **Savings: $20 (67% cheaper!)**

---

## ğŸ“ Project Structure

```
mcp-chatbot-client/
â”‚
â”œâ”€â”€ ğŸ“„ chatbot.py              # Core MCP chatbot implementation
â”œâ”€â”€ ğŸ“„ main.py                 # Application entry point
â”‚
â”œâ”€â”€ âš™ï¸  server_config.json     # MCP server configuration
â”œâ”€â”€ ğŸ” .env                    # API keys (gitignored)
â”‚
â”œâ”€â”€ ğŸ“‹ pyproject.toml          # Python dependencies
â”œâ”€â”€ ğŸ”’ uv.lock                 # Locked dependency versions
â”‚
â”œâ”€â”€ ğŸ“– README.md               # This file
â””â”€â”€ ğŸ“˜ GUIDE.md                # Detailed learning guide
```

---

## ğŸ§ª Development

### Testing Individual Servers

```bash
# Test filesystem server
npx -y @modelcontextprotocol/server-filesystem .

# Test fetch server
uvx --quiet mcp-server-fetch
```

### Building Custom MCP Servers

```python
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("my-custom-server")

@mcp.tool()
def process_text(text: str) -> str:
    """Process text and return result"""
    return f"Processed: {text.upper()}"

if __name__ == "__main__":
    mcp.run()
```

Add to config:

```json
{
  "my-server": {
    "command": "uv",
    "args": ["run", "my_server.py"]
  }
}
```

---

## ğŸ› Troubleshooting

### Common Issues

<details>
<summary><b>âŒ "ANTHROPIC_API_KEY not found"</b></summary>

**Solution:**

```bash
# Create .env file with your key
echo "ANTHROPIC_API_KEY=sk-ant-..." > .env

# Verify it's not tracked by git
git status  # .env should not appear
```

</details>

<details>
<summary><b>âŒ "npx: command not found"</b></summary>

**Solution:**

```bash
# Ubuntu/Debian
sudo apt install nodejs npm

# macOS
brew install node

# Windows
# Download from nodejs.org
```

</details>

<details>
<summary><b>âŒ "Failed to parse JSONRPC message"</b></summary>

**Solution:**
Add `--quiet` flag to suppress npm output:

```json
{
  "fetch": {
    "command": "uvx",
    "args": ["--quiet", "mcp-server-fetch"]
  }
}
```

</details>

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get involved:

```mermaid
graph LR
    A[ğŸ´ Fork Repo] --> B[ğŸŒ¿ Create Branch]
    B --> C[ğŸ’» Make Changes]
    C --> D[âœ… Test Changes]
    D --> E[ğŸ“ Commit]
    E --> F[â¬†ï¸ Push]
    F --> G[ğŸ”„ Open PR]

    style A fill:#e8f5e9,stroke:#2e7d32
    style B fill:#e3f2fd,stroke:#1976d2
    style C fill:#fff3e0,stroke:#f57c00
    style D fill:#f3e5f5,stroke:#7b1fa2
    style E fill:#fce4ec,stroke:#c2185b
    style F fill:#e0f2f1,stroke:#00897b
    style G fill:#e8eaf6,stroke:#3949ab
```

### Ways to Contribute

- ğŸ› **Report Bugs** - Open detailed issues
- ğŸ’¡ **Suggest Features** - Share your ideas
- ğŸ“– **Improve Documentation** - Help others learn
- ğŸ”§ **Submit Pull Requests** - Fix bugs, add features
- â­ **Star the Repository** - Show your support

### Code Guidelines

- Follow **PEP 8** style guide
- Add **type hints** to functions
- Include **docstrings** for classes and methods
- Write **clear commit messages**
- Add **tests** for new features

---

## ğŸ“š Resources

### Official Documentation

| Resource                                                           | Description                     |
| ------------------------------------------------------------------ | ------------------------------- |
| [MCP Docs](https://modelcontextprotocol.io/docs)                   | Complete protocol specification |
| [Python SDK](https://github.com/modelcontextprotocol/python-sdk)   | Official Python implementation  |
| [Anthropic API](https://docs.anthropic.com)                        | Claude API documentation        |
| [Server Registry](https://github.com/modelcontextprotocol/servers) | Available MCP servers           |

### Learning Resources

- ğŸ“ [DeepLearning.AI Course](https://learn.deeplearning.ai/courses/mcp-build-rich-context-ai-apps-with-anthropic) - Complete MCP course
- ğŸ“– [MCP Quickstart](https://modelcontextprotocol.io/quickstart/client) - Get started quickly
- ğŸ’¬ [Community Forum](https://github.com/orgs/modelcontextprotocol/discussions) - Ask questions

---

## ğŸ“ What You'll Learn

```mermaid
mindmap
  root((MCP Chatbot<br/>Client))
    MCP Protocol
      Client Architecture
      Server Communication
      Tool Discovery
      JSON-RPC 2.0
    Python Async
      AsyncExitStack
      Context Managers
      Concurrent Operations
    AI Integration
      Claude API
      Tool Calling
      Conversation Management
    Production Skills
      Error Handling
      Configuration Management
      Security Best Practices
      Scalable Design
```

---

## ğŸ“Š Project Stats

<div align="center">

| Metric                | Value               |
| --------------------- | ------------------- |
| **Lines of Code**     | ~200                |
| **Dependencies**      | 4 core packages     |
| **Supported Servers** | Unlimited â™¾ï¸        |
| **Tool Discovery**    | Automatic ğŸ¤–        |
| **Setup Time**        | < 5 minutes âš¡      |
| **Scalability**       | Production-ready ğŸš€ |

</div>

---

## ğŸ“ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **[Anthropic](https://www.anthropic.com/)** - For Claude AI and the MCP protocol
- **[DeepLearning.AI](https://www.deeplearning.ai/)** - For the comprehensive MCP course
- **MCP Community** - For reference implementations and community servers
- **Contributors** - Thank you for improving this project!

---

## ğŸŒŸ Star History

<div align="center">

**If this project helped you, please star it! â­**

It helps others discover the project and motivates continued development.

[![Star History Chart](https://api.star-history.com/svg?repos=jorgegoco/mcp-chatbot-client&type=Date)](https://star-history.com/#jorgegoco/mcp-chatbot-client&Date)

</div>

---

## ğŸ“¬ Support & Contact

<div align="center">

| Channel            | Link                                                                                                                                       |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ |
| ğŸ› **Issues**      | [GitHub Issues](https://github.com/jorgegoco/mcp-chatbot-client/issues)                                                                    |
| ğŸ’¬ **Discussions** | [GitHub Discussions](https://github.com/jorgegoco/mcp-chatbot-client/discussions)                                                          |
| ğŸ“§ **Email**       | jorgegoco70@gmail.com                                                                                                                      |
| ğŸ“ **Course**      | [MCP: Build Rich-Context AI Apps with Anthropic](https://www.deeplearning.ai/short-courses/mcp-build-rich-context-ai-apps-with-anthropic/) |

</div>

---

<div align="center">

**Built with â¤ï¸ using the Model Context Protocol**

**MCP is USB for AI - One Protocol, Unlimited Possibilities**

[â¬† Back to Top](#-mcp-chatbot-client)

</div>
